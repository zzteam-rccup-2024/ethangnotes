{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Course 3: YOLO - You Only Look Once\n",
    "\n",
    "The YOLO is a common library for recognizing objects in images. It is a very powerful tool for object detection. In this notebook, we will use a pre-trained model to detect objects in images. We will also use the YOLO model to detect objects in a video.\n",
    "\n",
    "The [official YOLO website](https://docs.ultralytics.com/) provides a lot of information about the YOLOv8 model.\n",
    "\n",
    "First, we should install the `ultralytics` library.\n",
    "\n",
    "```bash\n",
    "pip install ultralytics\n",
    "```\n",
    "\n",
    "Then, we can use `yolo` in the command or in the code.\n",
    "\n",
    "```bash\n",
    "yolo -version\n",
    "```\n",
    "\n",
    "## The YOLO model"
   ],
   "id": "75f0b196b1e01943"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:29:57.470573Z",
     "start_time": "2024-07-16T08:29:55.321394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "model = YOLO('yolov9e.pt')\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "model = model.to(device)"
   ],
   "id": "78f011a6d2a01f96",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predict the image\n",
    "\n",
    "Taking an example of a snapshot of *Honkai: Star Rail*, we can recognise items in the figure."
   ],
   "id": "71d939a1d797531b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:30:02.685787Z",
     "start_time": "2024-07-16T08:29:59.307364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('yolo/hsr.png')\n",
    "\n",
    "results = model([image])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    \n",
    "    result.show()"
   ],
   "id": "e195295673486885",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 person, 11 chairs, 1 dining table, 1 clock, 339.0ms\n",
      "Speed: 9.1ms preprocess, 339.0ms inference, 95.4ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predict the Video\n",
    "\n",
    "Taking the snap of Zenless Zone Zero of example."
   ],
   "id": "1b7a4712ab8783ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:31:41.200982Z",
     "start_time": "2024-07-16T08:31:32.027659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video = cv2.VideoCapture('./yolo/zzz.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        masks = result.masks\n",
    "        keypoints = result.keypoints\n",
    "        probs = result.probs\n",
    "        obb = result.obb\n",
    "        \n",
    "        # Assuming result.boxes returns a list of bounding boxes\n",
    "        if boxes is not None: \n",
    "            for box in boxes:\n",
    "                x, y, w, h = map(int, box.xywh.to('cpu')[0])\n",
    "                cv2.rectangle(frame, (x - w // 2, y - h // 2), (x + w // 2, x + h // 2), (0, 255, 0), 2)  # Draw bounding box\n",
    "\n",
    "        # Assuming result.keypoints returns a list of keypoints\n",
    "        if keypoints is not None:\n",
    "            for keypoint in keypoints:\n",
    "                for x, y in keypoint:\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)  # Draw keypoints\n",
    "    \n",
    "        # Assuming result.masks returns a list of masks\n",
    "        if masks is not None:\n",
    "            for mask in masks:\n",
    "                frame[mask] = (0, 255, 255)  # Apply mask to the frame\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.waitKey(1)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "77546bb62a5df68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x640 1 person, 1 backpack, 6 tvs, 1 laptop, 1 keyboard, 80.2ms\n",
      "Speed: 2.3ms preprocess, 80.2ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 1 bottle, 8 tvs, 1 laptop, 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 5.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 bottle, 10 tvs, 1 laptop, 44.3ms\n",
      "Speed: 2.5ms preprocess, 44.3ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 bottle, 11 tvs, 1 laptop, 1 mouse, 43.1ms\n",
      "Speed: 1.6ms preprocess, 43.1ms inference, 5.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 bottle, 1 cup, 9 tvs, 1 laptop, 43.4ms\n",
      "Speed: 2.1ms preprocess, 43.4ms inference, 5.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 bottle, 10 tvs, 1 laptop, 1 book, 41.3ms\n",
      "Speed: 1.8ms preprocess, 41.3ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 bottle, 1 cup, 9 tvs, 1 laptop, 44.7ms\n",
      "Speed: 1.5ms preprocess, 44.7ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 bottle, 1 cup, 9 tvs, 1 laptop, 1 clock, 43.1ms\n",
      "Speed: 1.7ms preprocess, 43.1ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 1 bottle, 1 cup, 11 tvs, 1 laptop, 42.5ms\n",
      "Speed: 1.4ms preprocess, 42.5ms inference, 7.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 11 tvs, 1 laptop, 1 remote, 1 clock, 44.2ms\n",
      "Speed: 2.4ms preprocess, 44.2ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 1 sports ball, 12 tvs, 1 laptop, 1 remote, 1 clock, 43.7ms\n",
      "Speed: 1.7ms preprocess, 43.7ms inference, 7.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 1 sports ball, 11 tvs, 1 laptop, 1 clock, 44.0ms\n",
      "Speed: 1.8ms preprocess, 44.0ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 10 tvs, 1 laptop, 1 clock, 42.6ms\n",
      "Speed: 1.6ms preprocess, 42.6ms inference, 7.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 10 tvs, 1 laptop, 43.3ms\n",
      "Speed: 1.7ms preprocess, 43.3ms inference, 6.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 9 tvs, 1 laptop, 44.4ms\n",
      "Speed: 1.7ms preprocess, 44.4ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 handbag, 7 tvs, 2 laptops, 1 clock, 44.0ms\n",
      "Speed: 1.8ms preprocess, 44.0ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 handbag, 8 tvs, 1 laptop, 1 mouse, 43.0ms\n",
      "Speed: 2.7ms preprocess, 43.0ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 handbag, 8 tvs, 1 laptop, 1 mouse, 1 cell phone, 43.9ms\n",
      "Speed: 1.8ms preprocess, 43.9ms inference, 6.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 handbag, 9 tvs, 2 laptops, 1 mouse, 1 cell phone, 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 person, 1 backpack, 42.6ms\n",
      "Speed: 1.6ms preprocess, 42.6ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.4ms\n",
      "Speed: 1.8ms preprocess, 44.4ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.7ms\n",
      "Speed: 2.8ms preprocess, 44.7ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.2ms\n",
      "Speed: 1.7ms preprocess, 45.2ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.1ms\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.7ms\n",
      "Speed: 2.6ms preprocess, 43.7ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 42.9ms\n",
      "Speed: 1.7ms preprocess, 42.9ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.8ms\n",
      "Speed: 1.4ms preprocess, 44.8ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.8ms\n",
      "Speed: 1.6ms preprocess, 45.8ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.0ms\n",
      "Speed: 1.8ms preprocess, 44.0ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.1ms\n",
      "Speed: 1.4ms preprocess, 44.1ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.0ms\n",
      "Speed: 1.5ms preprocess, 45.0ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.6ms\n",
      "Speed: 1.7ms preprocess, 44.6ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.4ms\n",
      "Speed: 1.5ms preprocess, 43.4ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.3ms\n",
      "Speed: 1.3ms preprocess, 44.3ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.5ms\n",
      "Speed: 1.7ms preprocess, 45.5ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.1ms\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.0ms\n",
      "Speed: 1.6ms preprocess, 43.0ms inference, 4.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.8ms\n",
      "Speed: 1.5ms preprocess, 44.8ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.6ms\n",
      "Speed: 1.5ms preprocess, 45.6ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.0ms\n",
      "Speed: 2.5ms preprocess, 44.0ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 46.0ms\n",
      "Speed: 1.5ms preprocess, 46.0ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.9ms\n",
      "Speed: 1.6ms preprocess, 43.9ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.9ms\n",
      "Speed: 1.6ms preprocess, 44.9ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.0ms\n",
      "Speed: 1.6ms preprocess, 43.0ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.9ms\n",
      "Speed: 1.4ms preprocess, 44.9ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.8ms\n",
      "Speed: 3.2ms preprocess, 43.8ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.5ms\n",
      "Speed: 3.0ms preprocess, 43.5ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.6ms\n",
      "Speed: 2.4ms preprocess, 45.6ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 4.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.1ms\n",
      "Speed: 1.7ms preprocess, 44.1ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 1.5ms preprocess, 43.6ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.5ms\n",
      "Speed: 2.5ms preprocess, 44.5ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.0ms\n",
      "Speed: 1.6ms preprocess, 44.0ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 45.5ms\n",
      "Speed: 1.6ms preprocess, 45.5ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.5ms\n",
      "Speed: 2.5ms preprocess, 43.5ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 42.5ms\n",
      "Speed: 1.6ms preprocess, 42.5ms inference, 136.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 30.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 4.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 4.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 42.6ms\n",
      "Speed: 1.6ms preprocess, 42.6ms inference, 28.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 44.3ms\n",
      "Speed: 1.7ms preprocess, 44.3ms inference, 40.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 43.4ms\n",
      "Speed: 1.4ms preprocess, 43.4ms inference, 37.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 42.5ms\n",
      "Speed: 2.9ms preprocess, 42.5ms inference, 33.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 42.9ms\n",
      "Speed: 1.8ms preprocess, 42.9ms inference, 39.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 44.3ms\n",
      "Speed: 1.9ms preprocess, 44.3ms inference, 6.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 43.9ms\n",
      "Speed: 1.8ms preprocess, 43.9ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 43.7ms\n",
      "Speed: 1.9ms preprocess, 43.7ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 43.7ms\n",
      "Speed: 2.1ms preprocess, 43.7ms inference, 6.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 44.2ms\n",
      "Speed: 1.9ms preprocess, 44.2ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 44.7ms\n",
      "Speed: 2.5ms preprocess, 44.7ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 train, 1 clock, 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 38.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 4.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 1 traffic light, 42.9ms\n",
      "Speed: 2.1ms preprocess, 42.9ms inference, 49.3ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 42.8ms\n",
      "Speed: 1.9ms preprocess, 42.8ms inference, 4.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 1.7ms preprocess, 43.6ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 288x640 (no detections), 43.6ms\n",
      "Speed: 2.5ms preprocess, 43.6ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 640)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, we can use the `yolo` command to detect objects in images and videos.",
   "id": "e8163dd1586ccb50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:36:15.599791Z",
     "start_time": "2024-07-16T08:34:10.046520Z"
    }
   },
   "cell_type": "code",
   "source": "!yolo detect predict --source=yolo/zzz.mp4 > ignore.txt",
   "id": "e177f5f5f7007984",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d226695bf0b35000"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
